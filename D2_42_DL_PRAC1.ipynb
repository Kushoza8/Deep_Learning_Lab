{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fESk4XMUqMRH"
   },
   "source": [
    "# NAME: KUSH OZA\n",
    " \n",
    " \n",
    "#  ROLL: 42\n",
    " \n",
    " \n",
    "#  BATCH: D2\n",
    " \n",
    " \n",
    "#  DL PRACTICAL -1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PROBLEM STATEMENT:\n",
    "Practical No. 1: Implementation of Single Perceptron and Creation of Logic Gates\n",
    "Tasks:\n",
    "    \n",
    "1. Single Perceptron Implementation:\n",
    "o Write a Python script to implement a single perceptron.\n",
    "o Include functions for initializing weights and bias, calculating the weighted \n",
    "sum, applying activation function (e.g., step function)\n",
    "o Test the perceptron on a simple binary classification problem.\n",
    "\n",
    "2. Creation of Logic Gates:\n",
    "o Use the single perceptron to create logic gates (AND, OR, NOT).\n",
    "o Define the input patterns for each gate and train the perceptron to produce the\n",
    "correct output.\n",
    "o Evaluate the trained perceptron on different inputs to verify its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WsLru1sSJDG3"
   },
   "outputs": [],
   "source": [
    "x_input=[0.1,0.5,0.2]\n",
    "w_weights=[0.7,0.9,0.5] #as here when we increase the weights or decrease the threshold we\n",
    "#will get the output as 1\n",
    "threshold=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2JtRBL7gqMTf"
   },
   "outputs": [],
   "source": [
    "def step(weighted_sum):\n",
    "  if weighted_sum >= threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fpLwf_PSqMV_"
   },
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "  weighted_sum=0\n",
    "  for x,w in zip(x_input,w_weights):\n",
    "    weighted_sum +=x*w\n",
    "    print(weighted_sum)\n",
    "  return step(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kndQGxw3qMYQ",
    "outputId": "96cba62d-0804-420b-a99e-7ca4d7472fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06999999999999999\n",
      "0.52\n",
      "0.62\n",
      "output =  1\n"
     ]
    }
   ],
   "source": [
    "output=perceptron()\n",
    "print(\"output = \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OMwhLgYqMau"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyWK9xhLstYP"
   },
   "source": [
    "change **threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JO97A0YbtCEI"
   },
   "outputs": [],
   "source": [
    "# //new weighth = original weight + error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2QgFFM9zPYQ"
   },
   "source": [
    "**Applying_perceprton_model of SKLEARN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nvH4pL7qzVMm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-aT70Wl2qEw",
    "outputId": "97164169-3b5f-49c8-d3e0-c0291ea6c206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(0, 1) = 0\n",
      "AND(1, 1) = 1\n",
      "AND(0, 0) = 0\n",
      "AND(1, 0) = 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unitStep(v):\n",
    "   if v >= 0:\n",
    "    return 1\n",
    "   else:\n",
    "    return 0\n",
    "\n",
    "def perceptronModel(x, w, b):\n",
    "   v = np.dot(w, x) + b\n",
    "   y = unitStep(v)\n",
    "   return y\n",
    "\n",
    "# AND Logic Function\n",
    "# w1 = 1, w2 = 1, b = -1.5\n",
    "def AND_logicFunction(x):\n",
    "   w = np.array([1, 1])\n",
    "   b = -1.5\n",
    "   return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
    "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfARmjwvHRg_",
    "outputId": "4621a818-684c-4e8e-9423-749c3580dcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(0, 1) = 1\n",
      "AND(1, 1) = 1\n",
      "AND(0, 0) = 0\n",
      "AND(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "# importing Python library\n",
    "import numpy as np\n",
    "\n",
    "# define Unit Step Function\n",
    "def unitStep(v):\n",
    "   if v >= 0:\n",
    "    return 1\n",
    "   else:\n",
    "    return 0\n",
    "\n",
    "# design Perceptron Model\n",
    "def perceptronModel(x, w, b):\n",
    "   v = np.dot(w, x) + b\n",
    "   y = unitStep(v)\n",
    "   return y\n",
    "\n",
    "# OR Logic Function\n",
    "\n",
    "# w1 = 1, w2 = 1, b = -1.5\n",
    "def AND_logicFunction(x):\n",
    "   w = np.array([1, 1])\n",
    "   b = -0.5\n",
    "   return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
    "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0xPNrlmHRlf",
    "outputId": "1511a7b1-7750-491f-f7a5-5421e00b8049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(0, 1) = 0\n",
      "AND(1, 1) = 1\n",
      "AND(0, 0) = 0\n",
      "AND(1, 0) = 0\n"
     ]
    }
   ],
   "source": [
    "# AND Logic Function\n",
    "# w1 = 1, w2 = 1, b = -1.5\n",
    "def AND_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    b = -1.5\n",
    "    return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model for AND gate\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
    "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
    "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYA0iAE_HRno",
    "outputId": "de9db9a2-be1a-423e-d527-d38181236293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR(0, 1) = 1\n",
      "OR(1, 1) = 1\n",
      "OR(0, 0) = 0\n",
      "OR(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "# OR Logic Function\n",
    "# w1 = 1, w2 = 1, b = -0.5\n",
    "def OR_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    b = -0.5\n",
    "    return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model for OR gate\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"OR({}, {}) = {}\".format(0, 1, OR_logicFunction(test1)))\n",
    "print(\"OR({}, {}) = {}\".format(1, 1, OR_logicFunction(test2)))\n",
    "print(\"OR({}, {}) = {}\".format(0, 0, OR_logicFunction(test3)))\n",
    "print(\"OR({}, {}) = {}\".format(1, 0, OR_logicFunction(test4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eIA7CGTHRrQ",
    "outputId": "3420bb9d-9118-49aa-e1a1-17b79b2b4620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT(1) = 0\n",
      "NOT(0) = 1\n"
     ]
    }
   ],
   "source": [
    "# importing Python library\n",
    "import numpy as np\n",
    "\n",
    "# define Unit Step Function\n",
    "def unitStep(v):\n",
    "    if v >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# design Perceptron Model\n",
    "def perceptronModel(x, w, b):\n",
    "    v = np.dot(w, x) + b\n",
    "    y = unitStep(v)\n",
    "    return y\n",
    "\n",
    "# NOT Logic Function\n",
    "# w = -1, b = 0.5\n",
    "def NOT_logicFunction(x):\n",
    "    w = -1\n",
    "    b = 0.5\n",
    "    return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test1 = np.array(1)\n",
    "test2 = np.array(0)\n",
    "\n",
    "print(\"NOT({}) = {}\".format(1, NOT_logicFunction(test1)))\n",
    "print(\"NOT({}) = {}\".format(0, NOT_logicFunction(test2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tbm5lazHRt-",
    "outputId": "33dbd5ac-5654-4c4e-e955-31e29b5baf88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR(0, 1) = 1\n",
      "XOR(1, 1) = 0\n",
      "XOR(0, 0) = 0\n",
      "XOR(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "# importing Python library\n",
    "import numpy as np\n",
    "\n",
    "# define Unit Step Function\n",
    "def unitStep(v):\n",
    "    if v >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# design Perceptron Model\n",
    "def perceptronModel(x, w, b):\n",
    "    v = np.dot(w, x) + b\n",
    "    y = unitStep(v)\n",
    "    return y\n",
    "\n",
    "# NOT Logic Function\n",
    "# wNOT = -1, bNOT = 0.5\n",
    "def NOT_logicFunction(x):\n",
    "    wNOT = -1\n",
    "    bNOT = 0.5\n",
    "    return perceptronModel(x, wNOT, bNOT)\n",
    "\n",
    "# AND Logic Function\n",
    "# here w1 = wAND1 = 1,\n",
    "# w2 = wAND2 = 1, bAND = -1.5\n",
    "def AND_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    bAND = -1.5\n",
    "    return perceptronModel(x, w, bAND)\n",
    "\n",
    "# OR Logic Function\n",
    "# w1 = 1, w2 = 1, bOR = -0.5\n",
    "def OR_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    bOR = -0.5\n",
    "    return perceptronModel(x, w, bOR)\n",
    "\n",
    "# XOR Logic Function\n",
    "# with AND, OR and NOT\n",
    "# function calls in sequence\n",
    "def XOR_logicFunction(x):\n",
    "    y1 = AND_logicFunction(x)\n",
    "    y2 = OR_logicFunction(x)\n",
    "    y3 = NOT_logicFunction(y1)\n",
    "    final_x = np.array([y2, y3])\n",
    "    finalOutput = AND_logicFunction(final_x)\n",
    "    return finalOutput\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
    "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1A.NOR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLbQnuYzHRwg",
    "outputId": "cabc4f27-58d9-42a6-b14f-06724be1f1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOR(0, 1) = 0\n",
      "NOR(1, 1) = 0\n",
      "NOR(0, 0) = 1\n",
      "NOR(1, 0) = 0\n"
     ]
    }
   ],
   "source": [
    "# importing Python library\n",
    "import numpy as np\n",
    "\n",
    "# define Unit Step Function\n",
    "def unitStep(v):\n",
    "   if v <= 0:\n",
    "    return 1\n",
    "   else:\n",
    "    return 0\n",
    "\n",
    "# design Perceptron Model\n",
    "def perceptronModel(x, w, b):\n",
    "   v = np.dot(w, x) + b\n",
    "   y = unitStep(v)\n",
    "   return y\n",
    "\n",
    "# NOR Logic Function\n",
    "\n",
    "# w1 = 1, w2 = 1, b = -1.5\n",
    "def NOR_logicFunction(x):\n",
    "   w = np.array([1, 1])\n",
    "   b = -0.5\n",
    "   return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"NOR({}, {}) = {}\".format(0, 1, NOR_logicFunction(test1)))\n",
    "print(\"NOR({}, {}) = {}\".format(1, 1, NOR_logicFunction(test2)))\n",
    "print(\"NOR({}, {}) = {}\".format(0, 0, NOR_logicFunction(test3)))\n",
    "print(\"NOR({}, {}) = {}\".format(1, 0, NOR_logicFunction(test4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1A.NAND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrhNG86OHR0u",
    "outputId": "e9dca570-6ecc-40bc-88cb-c01d43f2864a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND(0, 1) = 1\n",
      "NAND(1, 1) = 0\n",
      "NAND(0, 0) = 1\n",
      "NAND(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unitStep(v):\n",
    "    if v <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def perceptronModel(x, w, b):\n",
    "    v = np.dot(w, x) + b\n",
    "    y = unitStep(v)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "# w1 = -2, w2 = -2, b = 3\n",
    "def NAND_logicFunction(x):\n",
    "    w = np.array([-2, -2])\n",
    "    b = 3\n",
    "    return perceptronModel(x, w, b)\n",
    "\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"NAND({}, {}) = {}\".format(0, 1, NAND_logicFunction(test1)))\n",
    "print(\"NAND({}, {}) = {}\".format(1, 1, NAND_logicFunction(test2)))\n",
    "print(\"NAND({}, {}) = {}\".format(0, 0, NAND_logicFunction(test3)))\n",
    "print(\"NAND({}, {}) = {}\".format(1, 0, NAND_logicFunction(test4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50Hqm6CYHR6O",
    "outputId": "e04e19b3-9e52-4f86-e789-63329ebda154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE(0, 0, 0) = 1\n",
      "EXAMPLE(0, 0, 1) = 1\n",
      "EXAMPLE(0, 1, 0) = 1\n",
      "EXAMPLE(0, 1, 1) = 1\n",
      "EXAMPLE(1, 0, 0) = 1\n",
      "EXAMPLE(1, 0, 1) = 1\n",
      "EXAMPLE(1, 1, 0) = 1\n",
      "EXAMPLE(1, 1, 1) = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unitStep(v):\n",
    "    if v > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def perceptronModel(x, w, b):\n",
    "    v = np.dot(w, x) + b\n",
    "    y = unitStep(v)\n",
    "    return y\n",
    "\n",
    "def EXAMPLE_logicFunction(x):\n",
    "    w = np.array([1, 1, 1])\n",
    "    b = 0.5\n",
    "    return perceptronModel(x, w, b)\n",
    "\n",
    "# testing the Perceptron Model\n",
    "test0 = np.array([0, 0, 0])\n",
    "test1 = np.array([0, 0, 1])\n",
    "test2 = np.array([0, 1, 0])\n",
    "test3 = np.array([0, 1, 1])\n",
    "test4 = np.array([1, 0, 0])\n",
    "test5 = np.array([1, 0, 1])\n",
    "test6 = np.array([1, 1, 0])\n",
    "test7 = np.array([1, 1, 1])\n",
    "\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(0, 0, 0, EXAMPLE_logicFunction(test0)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(0, 0, 1, EXAMPLE_logicFunction(test1)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(0, 1, 0, EXAMPLE_logicFunction(test2)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(0, 1, 1, EXAMPLE_logicFunction(test3)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(1, 0, 0, EXAMPLE_logicFunction(test4)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(1, 0, 1, EXAMPLE_logicFunction(test5)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(1, 1, 0, EXAMPLE_logicFunction(test6)))\n",
    "print(\"EXAMPLE({}, {}, {}) = {}\".format(1, 1, 1, EXAMPLE_logicFunction(test7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aC765rct3fdZ",
    "outputId": "395bdcab-014c-4af9-905b-a7bbbcc62ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F(-1, -1, -1) = 0\n",
      "F(-1, -1, 1) = 0\n",
      "F(-1, 1, -1) = 0\n",
      "F(-1, 1, 1) = 0\n",
      "F(1, -1, -1) = 0\n",
      "F(1, -1, 1) = 0\n",
      "F(1, 1, -1) = 0\n",
      "F(1, 1, 1) = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unitStep(v):\n",
    "  if v >  2:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def perceptronModel(x, w, b):\n",
    "  v = np.dot(w, x) + b\n",
    "  y = unitStep(v)\n",
    "  return y\n",
    "\n",
    "# AND Logic Function\n",
    "# w1 = 1, w2 = 1, w3 = 1, b = 1\n",
    "def F_logicFunction(x):\n",
    "  w = np.array([1, 1, 1])\n",
    "  b = 1\n",
    "  return perceptronModel(x, w, b)\n",
    "\n",
    "test1 = np.array([-1, -1, -1])\n",
    "test2 = np.array([-1, -1, 1])\n",
    "test3 = np.array([-1,  1, -1])\n",
    "test4 = np.array([-1,  1,  1])\n",
    "test5 = np.array([ 1, -1, -1])\n",
    "test6 = np.array([ 1, -1,  1])\n",
    "test7 = np.array([ 1,  1, -1])\n",
    "test8 = np.array([ 1,  1,  1])\n",
    "\n",
    "print(\"F({}, {}, {}) = {}\".format(-1, -1, -1, F_logicFunction(test1)))\n",
    "print(\"F({}, {}, {}) = {}\".format(-1, -1,  1, F_logicFunction(test2)))\n",
    "print(\"F({}, {}, {}) = {}\".format(-1,  1, -1, F_logicFunction(test3)))\n",
    "print(\"F({}, {}, {}) = {}\".format(-1,  1,  1, F_logicFunction(test4)))\n",
    "print(\"F({}, {}, {}) = {}\".format( 1, -1, -1, F_logicFunction(test5)))\n",
    "print(\"F({}, {}, {}) = {}\".format( 1, -1,  1, F_logicFunction(test6)))\n",
    "print(\"F({}, {}, {}) = {}\".format( 1,  1, -1, F_logicFunction(test7)))\n",
    "print(\"F({}, {}, {}) = {}\".format( 1,  1,  1, F_logicFunction(test8)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1B. Implement Perceptron learning algorithm for classification of following points {P0(-1,-1,-1) , P1(-\n",
    "1,-1,1) , P2(-1,1,-1), P3(-1,1,1) ,P4(1,-1,-1) , P5(1,-1,1) , P6(1,1,-1), P7(1,1,1)} in to two classes:\n",
    "C1={P7 (1,1,1)}\n",
    "C2={ P0(-1,-1,-1), P1(-1,-1,1) , P2(-1,1,-1) , P3(-1,1,1) ,P4(1,-1,-1), P5(1,-1,1) , P6(1,1,-1) }\n",
    "\n",
    "\n",
    "1C.Write a python program to find the number of linearly separable problems out of total binary\n",
    "classification problems on {P0(-1,-1,-1), P1(-1,-1,1) , P2(-1,1,-1) , P3(-1,1,1) ,P4(1,-1,-1), P5(1,-1,1) ,\n",
    "P6(1,1,-1) , P7(1,1,1) }."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "hf7gLTSh5cJQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#define the data points\n",
    "data_points = {\n",
    "    'P0' : np.array([-1, -1, -1]),\n",
    "    'P1' : np.array([-1, -1, 1]),\n",
    "    'P2' : np.array([-1,  1, -1]),\n",
    "    'P3' : np.array([-1,  1, 1]),\n",
    "    'P4' : np.array([ 1, -1, -1]),\n",
    "    'P5' : np.array([ 1, -1,  1]),\n",
    "    'P6' : np.array([ 1,  1, -1]),\n",
    "    'P7' : np.array([ 1,  1,  1])\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "NbK4aEuY7URp"
   },
   "outputs": [],
   "source": [
    "c1=['P7']\n",
    "c2=['P0','P1','P2','P3','P4','P5','P6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iemr2GI69UKY",
    "outputId": "832a9f43-e153-40d4-e064-d1c390330de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#initialize weights and bias\n",
    "\n",
    "weights=np.zeros(len(data_points['P1']))\n",
    "bias=0\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "1Tx1fJZK9uIo"
   },
   "outputs": [],
   "source": [
    "# Define the learning rates\n",
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Fe3zAlSM97Hy"
   },
   "outputs": [],
   "source": [
    "#define the epochs\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "NUatwaGa97Ug"
   },
   "outputs": [],
   "source": [
    "# Perceptron Learning Algorithm\n",
    "\n",
    "for epoch in range(epoch):\n",
    "  for point in c2:\n",
    "    x=data_points[point]\n",
    "    y=1 # C2 is the positive class\n",
    "\n",
    "    #calculate the prediction\n",
    "\n",
    "    prediction=np.dot(weights,x)+bias\n",
    "\n",
    "    #update weights and bias based on the prediction\n",
    "    if prediction<=0:\n",
    "      weights +=learning_rate * x\n",
    "      bias += learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "zfyNNNdD-T9g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights: [-0.01  0.01  0.01  0.01]\n",
      "Learned bias: -0.01\n",
      "Point P0 is predicted to belong to Class C2\n",
      "Point P1 is predicted to belong to Class C2\n",
      "Point P2 is predicted to belong to Class C2\n",
      "Point P3 is predicted to belong to Class C2\n",
      "Point P4 is predicted to belong to Class C2\n",
      "Point P5 is predicted to belong to Class C2\n",
      "Point P6 is predicted to belong to Class C2\n",
      "Point P7 is predicted to belong to Class C1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features, learning_rate=0.01):\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, x):\n",
    "        return 1 if (np.dot(self.weights, x) + self.bias) >= 0 else -1\n",
    "\n",
    "    def train(self, X, y, epochs=100):\n",
    "        for _ in range(epochs):\n",
    "            for i in range(len(X)):\n",
    "                prediction = self.predict(X[i])\n",
    "                if prediction != y[i]:\n",
    "                    self.weights += self.learning_rate * y[i] * X[i]\n",
    "                    self.bias += self.learning_rate * y[i]\n",
    "\n",
    "# Define the points and their classes\n",
    "points = {\n",
    "    'P0': np.array([-1, -1, -1]),\n",
    "    'P1': np.array([-1, -1, 1]),\n",
    "    'P2': np.array([-1, 1, -1]),\n",
    "    'P3': np.array([-1, 1, 1]),\n",
    "    'P4': np.array([1, -1, -1]),\n",
    "    'P5': np.array([1, -1, 1]),\n",
    "    'P6': np.array([1, 1, -1]),\n",
    "    'P7': np.array([1, 1, 1])\n",
    "}\n",
    "\n",
    "class_C1 = ['P7']  # Class C1 contains only point P7\n",
    "class_C2 = ['P0', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6']  # Class C2 contains all other points\n",
    "\n",
    "X = np.array([points[key] for key in points])\n",
    "X = np.insert(X, 0, 1, axis=1) \n",
    "\n",
    "\n",
    "y = np.array([1 if key in class_C1 else -1 for key in points])\n",
    "\n",
    "\n",
    "perceptron = Perceptron(num_features=len(X[0]))\n",
    "perceptron.train(X, y)\n",
    "\n",
    "print(\"Learned weights:\", perceptron.weights)\n",
    "print(\"Learned bias:\", perceptron.bias)\n",
    "\n",
    "for key, point in points.items():\n",
    "    predicted_class = perceptron.predict(np.insert(point, 0, 1))\n",
    "    print(f\"Point {key} is predicted to belong to {'Class C1' if predicted_class == 1 else 'Class C2'}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
